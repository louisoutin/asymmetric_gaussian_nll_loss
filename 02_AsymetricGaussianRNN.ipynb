{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import List\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import TimeseriesDataset\n",
    "from losses import asymetric_gaussian_nll_loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class Configs:\n",
    "    csv_path : str = \"datasets/synthetic_sin_w_asym_noise.csv\"\n",
    "    model_output_path: str = \"runs/asymetric_gaussian_rnn\"\n",
    "    features = ['sin']\n",
    "    targets = ['target']\n",
    "    input_length: int = 10\n",
    "    learning_rate: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    epochs: int = 50\n",
    "    early_stopping: int = 4\n",
    "    batch_size: int = 32\n",
    "    lstm_hidden_size: int = 32\n",
    "    lstm_num_layers: int = 1\n",
    "    device: str = \"cuda:0\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset = pd.read_csv(Configs.csv_path)\n",
    "dataset = dataset.set_index(\"date\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_dataset = TimeseriesDataset(dataset, \n",
    "                                  features=Configs.features,\n",
    "                                  targets=Configs.targets,\n",
    "                                  input_length=Configs.input_length,\n",
    "                                  start_date=\"1980-01\",\n",
    "                                  end_date=\"1990-01\",\n",
    "                                  scaler=None)\n",
    "\n",
    "val_dataset = TimeseriesDataset(dataset, \n",
    "                                features=Configs.features,\n",
    "                                targets=Configs.targets,\n",
    "                                input_length=Configs.input_length,\n",
    "                                start_date=\"1990-01\",\n",
    "                                end_date=\"2000-01\",\n",
    "                                scaler=train_dataset.scaler)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=Configs.batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=Configs.batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class AsymmetricGaussianLSTM(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        features: List[str] = ['col'],\n",
    "        targets: List[str] = ['col'],\n",
    "        lstm_hidden_size: int = 32,\n",
    "        lstm_num_layers: int = 1,\n",
    "        learning_rate: float = 1e-3,\n",
    "        weight_decay: float = 1e-4,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        print(f\"Init model, hparams:\\n{self.hparams}\\n\")\n",
    "        self.lstm_encoder = nn.GRU(\n",
    "            len(features), lstm_hidden_size, lstm_num_layers, batch_first=True\n",
    "        )\n",
    "        self.mu = nn.Linear(lstm_hidden_size, len(targets))\n",
    "        self.sigma_left = nn.Linear(lstm_hidden_size, len(targets))\n",
    "        self.sigma_right = nn.Linear(lstm_hidden_size, len(targets))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, _ = self.lstm_encoder(x)\n",
    "        h = h[:, -1, :]  # last rnn hidden state\n",
    "        mu = self.mu(h)\n",
    "        sigma_left = self.sigma_left(h)\n",
    "        sigma_left = F.elu(sigma_left) + 1.0 + 1e-15\n",
    "        sigma_right = self.sigma_right(h)\n",
    "        sigma_right = F.elu(sigma_right) + 1.0 + 1e-15\n",
    "        return mu, sigma_left, sigma_right\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch, log_mode: str = \"train\"):\n",
    "        \"\"\" \"\"\"\n",
    "        x, y = batch[0], batch[1]\n",
    "        x = x.to(dtype=torch.float32, device=self.device)\n",
    "        y = y.to(dtype=torch.float32, device=self.device)\n",
    "        mu, sigma_left, sigma_right = self(x)\n",
    "        loss = asymetric_gaussian_nll_loss(mu, y, sigma_left, sigma_right)\n",
    "        # loss = F.mse_loss(mu, y)\n",
    "        self.log(f\"{log_mode}_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._step(batch, log_mode=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._step(batch, log_mode=\"val\")\n",
    "\n",
    "    def predict(self, data_loader: torch.utils.data.DataLoader):\n",
    "        \"\"\"Predict function for inference/testing the model\n",
    "\n",
    "        Args:\n",
    "            data_loader (torch.utils.data.DataLoader): You should pass the test loader here\n",
    "\n",
    "        Returns:\n",
    "            tuple(np.arr, np.arr): predictions, ground_truth\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        result_dfs = []\n",
    "        for x, y, date in data_loader:\n",
    "            with torch.no_grad():\n",
    "                x = x.to(dtype=torch.float32, device=self.device)\n",
    "                y = y.to(dtype=torch.float32, device=self.device)\n",
    "                mu, sigma_left, sigma_right = self(x)\n",
    "                mu = mu.detach().cpu().numpy()\n",
    "                sigma_left = sigma_left.detach().cpu().numpy()\n",
    "                sigma_right = sigma_right.detach().cpu().numpy()\n",
    "                y = y.detach().cpu().numpy()\n",
    "                df_y = pd.DataFrame(index=date, data=y, columns=[f\"y_{c}\" for c in self.hparams.targets])\n",
    "                df_mu = pd.DataFrame(index=date, data=mu, columns=[f\"mu_{c}\" for c in self.hparams.targets])\n",
    "                df_sigma_left = pd.DataFrame(index=date, data=sigma_left, columns=[f\"sigma_left_{c}\" for c in self.hparams.targets])\n",
    "                df_sigma_right = pd.DataFrame(index=date, data=sigma_right, columns=[f\"sigma_right_{c}\" for c in self.hparams.targets])\n",
    "                df_res = pd.concat([df_mu, df_y, df_sigma_left, df_sigma_right], axis=1)\n",
    "                result_dfs.append(df_res)\n",
    "        return pd.concat(result_dfs)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = AsymmetricGaussianLSTM(\n",
    "    features=Configs.features,\n",
    "    targets=Configs.targets,\n",
    "    learning_rate=Configs.learning_rate,\n",
    "    weight_decay=Configs.weight_decay,\n",
    "    lstm_hidden_size=Configs.lstm_hidden_size,\n",
    "    lstm_num_layers=Configs.lstm_num_layers\n",
    "    )\n",
    "model.to(Configs.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_loss',\n",
    "   patience=Configs.early_stopping,\n",
    "   verbose=True\n",
    ")\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", save_weights_only=True)\n",
    "\n",
    "if Configs.device == \"cpu\":\n",
    "    trainer = pl.Trainer(default_root_dir=Configs.model_output_path,\n",
    "                         max_epochs=Configs.epochs,\n",
    "                         callbacks=[checkpoint_callback, early_stop_callback])\n",
    "else:\n",
    "    device_name, device_id = Configs.device.split(\":\")  \n",
    "    assert device_name == \"cuda\", \"Configs>device should be cpu or cuda\"  \n",
    "    trainer = pl.Trainer(default_root_dir=Configs.model_output_path,\n",
    "                         max_epochs=Configs.epochs,\n",
    "                         callbacks=[checkpoint_callback, early_stop_callback],\n",
    "                         gpus=device_id)\n",
    "\n",
    "trainer.fit(model, \n",
    "            train_dataloader=train_loader, \n",
    "            val_dataloaders=val_loader)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = AsymmetricGaussianLSTM.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "model.to(Configs.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_dataset = TimeseriesDataset(dataset, \n",
    "                                features=Configs.features,\n",
    "                                targets=Configs.targets,\n",
    "                                input_length=Configs.input_length,\n",
    "                                start_date=\"2020-01\",\n",
    "                                end_date=\"2021-02\",\n",
    "                                scaler=train_dataset.scaler)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                        batch_size=Configs.batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_preds = model.predict(test_loader)\n",
    "df_preds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "y = df_preds[\"y_target\"]\n",
    "mu = df_preds[\"mu_target\"]\n",
    "sigma_left = df_preds[\"sigma_left_target\"]\n",
    "sigma_right = df_preds[\"sigma_right_target\"]\n",
    "\n",
    "ax.plot(df_preds.index, y, '-', color=\"blue\")\n",
    "ax.plot(df_preds.index, mu, '-', color=\"red\")\n",
    "ax.fill_between(df_preds.index, \n",
    "                mu - 3 * sigma_left, \n",
    "                mu + 3 * sigma_right, \n",
    "                alpha=0.8)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "9aaa7a099c7d512caf7cdf8029bc66d33bec096773b43c3b90593491b23668ba"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}